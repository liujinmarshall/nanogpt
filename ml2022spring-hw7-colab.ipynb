{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T19:03:37.179026Z",
     "iopub.status.busy": "2023-07-11T19:03:37.17865Z",
     "iopub.status.idle": "2023-07-11T19:03:37.18801Z",
     "shell.execute_reply": "2023-07-11T19:03:37.186287Z",
     "shell.execute_reply.started": "2023-07-11T19:03:37.178996Z"
    },
    "id": "xvSGDbExff_I"
   },
   "source": [
    "# **Homework 7 - Bert (Question Answering)**\n",
    "\n",
    "If you have any questions, feel free to email us at mlta-2022-spring@googlegroups.com\n",
    "\n",
    "\n",
    "\n",
    "Slide:    [Link](https://docs.google.com/presentation/d/1H5ZONrb2LMOCixLY7D5_5-7LkIaXO6AGEaV2mRdTOMY/edit?usp=sharing)　Kaggle: [Link](https://www.kaggle.com/c/ml2022spring-hw7)　Data: [Link](https://drive.google.com/uc?id=1AVgZvy3VFeg0fX-6WQJMHPVrx3A-M1kb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGOr_eS3wJJf"
   },
   "source": [
    "## Task description\n",
    "- Chinese Extractive Question Answering\n",
    "  - Input: Paragraph + Question\n",
    "  - Output: Answer\n",
    "\n",
    "- Objective: Learn how to fine tune a pretrained model on downstream task using transformers\n",
    "\n",
    "- Todo\n",
    "    - Fine tune a pretrained chinese BERT model\n",
    "    - Change hyperparameters (e.g. doc_stride)\n",
    "    - Apply linear learning rate decay\n",
    "    - Try other pretrained models\n",
    "    - Improve preprocessing\n",
    "    - Improve postprocessing\n",
    "- Training tips\n",
    "    - Automatic mixed precision\n",
    "    - Gradient accumulation\n",
    "    - Ensemble\n",
    "\n",
    "- Estimated training time (tesla t4 with automatic mixed precision enabled)\n",
    "    - Simple: 8mins\n",
    "    - Medium: 8mins\n",
    "    - Strong: 25mins\n",
    "    - Boss: 2.5hrs\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJ1fSAJE2oaC"
   },
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YPrc4Eie9Yo5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 10 19:27:49 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 552.41       CUDA Version: 12.4     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        On  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   35C    P8              11W / 320W |   2008MiB / 16376MiB |     16%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1049      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Download link 1\n",
    "#!gdown --id '1AVgZvy3VFeg0fX-6WQJMHPVrx3A-M1kb' --output hw7_data.zip\n",
    "\n",
    "# Download Link 2 (if the above link fails)\n",
    "#!gdown --id '1qwjbRjq481lHsnTrrF4OjKQnxzgoLEFR' --output hw7_data.zip\n",
    "\n",
    "# Download Link 3 (if the above link fails)\n",
    "# !gdown --id '1QXuWjNRZH6DscSd6QcRER0cnxmpZvijn' --output hw7_data.zip\n",
    "\n",
    "#!unzip -o hw7_data.zip\n",
    "\n",
    "# For this HW, K80 < P4 < T4 < P100 <= T4(fp16) < V100\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TevOvhC03m0h"
   },
   "source": [
    "## Install transformers\n",
    "\n",
    "Documentation for the toolkit:　https://huggingface.co/transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tbxWFX_jpDom"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (4.44.0)\n",
      "Requirement already satisfied: torch in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (3.9.1.post1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# You are allowed to change version of transformers or use other toolkits\n",
    "#!pip install transformers==4.5.0\n",
    "!pip install transformers torch\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dKM4yCh4LI_"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WOTHHtWJoahe"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW, BertForQuestionAnswering, BertTokenizerFast\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "def same_seeds(seed):\n",
    "\t  torch.manual_seed(seed)\n",
    "\t  if torch.cuda.is_available():\n",
    "\t\t    torch.cuda.manual_seed(seed)\n",
    "\t\t    torch.cuda.manual_seed_all(seed)\n",
    "\t  np.random.seed(seed)\n",
    "\t  random.seed(seed)\n",
    "\t  torch.backends.cudnn.benchmark = False\n",
    "\t  torch.backends.cudnn.deterministic = True\n",
    "same_seeds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install accelerate --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7pBtSZP1SKQO"
   },
   "outputs": [],
   "source": [
    "# Change \"fp16_training\" to True to support automatic mixed precision training (fp16)\n",
    "fp16_training = True\n",
    "\n",
    "if fp16_training:\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator(mixed_precision=\"bf16\", gradient_accumulation_steps=4)\n",
    "    device = accelerator.device\n",
    "else:\n",
    "    device = device\n",
    "\n",
    "# Documentation for the toolkit:  https://huggingface.co/docs/accelerate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YgXHuVLp_6j"
   },
   "source": [
    "## Load Model and Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xyBCYGjAp3ym"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7198c8d2d6e54542ba0a7baaef6f655a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4059ade4e8c4498e9cab641d158bbbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a42dbd45817476ca875b9e9b388558e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3177af641593445dbb82cb78a1cf6a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc380bc61085425aa10e2973d66e1d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained(\"google-bert/bert-large-uncased\").to(device)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-large-uncased\")\n",
    "\n",
    "# FacebookAI/xlm-roberta-base\n",
    "# google-bert/bert-base-multilingual-cased\n",
    "# google-bert/bert-base-chinese\n",
    "# google-bert/bert-large-uncased\n",
    "# FacebookAI/roberta-large\n",
    "\n",
    "# You can safely ignore the warning message (it pops up because new prediction heads for QA are initialized randomly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Td-GTmk5OW4"
   },
   "source": [
    "## Read Data\n",
    "\n",
    "- Training set: 31690 QA pairs\n",
    "- Dev set: 4131  QA pairs\n",
    "- Test set: 4957  QA pairs\n",
    "\n",
    "- {train/dev/test}_questions:\n",
    "  - List of dicts with the following keys:\n",
    "   - id (int)\n",
    "   - paragraph_id (int)\n",
    "   - question_text (string)\n",
    "   - answer_text (string)\n",
    "   - answer_start (int)\n",
    "   - answer_end (int)\n",
    "- {train/dev/test}_paragraphs:\n",
    "  - List of strings\n",
    "  - paragraph_ids in questions correspond to indexs in paragraphs\n",
    "  - A paragraph may be used by several questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:[./]\n",
      "+--ml2022spring-hw7.zip\n",
      "+--result_lr_update.csv\n",
      "+--result_start_end_swap.csv\n",
      "+--saved_model\n",
      "|      +--model.safetensors\n",
      "|      +--config.json\n",
      "+--result_original.csv\n",
      "+--result.csv\n",
      "+--.ipynb_checkpoints\n",
      "|      +--ml2022spring-hw7-colab-checkpoint.ipynb\n",
      "|      +--result_start_end_swap-checkpoint.csv\n",
      "|      +--hw7_train-checkpoint.json\n",
      "|      +--result_original-checkpoint.csv\n",
      "|      +--hw7_test-checkpoint.json\n",
      "+--hw7_test.json\n",
      "+--hw7_train.json\n",
      "+--hw7_dev.json\n",
      "+--ml2022spring-hw7-colab.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "def dfs_showdir(path, depth):\n",
    "    if depth == 0:\n",
    "        print(\"root:[\" + path + \"]\")\n",
    "\n",
    "    for item in os.listdir(path):\n",
    "        if '.git' not in item:\n",
    "            print(\"|      \" * depth + \"+--\" + item)\n",
    "\n",
    "            newitem = path +'/'+ item\n",
    "            if os.path.isdir(newitem):\n",
    "                dfs_showdir(newitem, depth +1)\n",
    "\n",
    "dfs_showdir('./', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NvX7hlepogvu"
   },
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    with open(file, 'r', encoding=\"utf-8\") as reader:\n",
    "        data = json.load(reader)\n",
    "    return data[\"questions\"], data[\"paragraphs\"]\n",
    "\n",
    "# train_questions, train_paragraphs = read_data(\"hw7_train.json\")\n",
    "# dev_questions, dev_paragraphs = read_data(\"hw7_dev.json\")\n",
    "# test_questions, test_paragraphs = read_data(\"hw7_test.json\")\n",
    "train_questions, train_paragraphs = read_data(\"hw7_train.json\")\n",
    "dev_questions, dev_paragraphs = read_data(\"hw7_dev.json\")\n",
    "test_questions, test_paragraphs = read_data(\"hw7_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fm0rpTHq0e4N"
   },
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rTZ6B70Hoxie"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Tokenize questions and paragraphs separately\n",
    "# 「add_special_tokens」 is set to False since special tokens will be added when tokenized questions and paragraphs are combined in datset __getitem__\n",
    "\n",
    "train_questions_tokenized = tokenizer([train_question[\"question_text\"] for train_question in train_questions], add_special_tokens=False)\n",
    "dev_questions_tokenized = tokenizer([dev_question[\"question_text\"] for dev_question in dev_questions], add_special_tokens=False)\n",
    "test_questions_tokenized = tokenizer([test_question[\"question_text\"] for test_question in test_questions], add_special_tokens=False)\n",
    "\n",
    "train_paragraphs_tokenized = tokenizer(train_paragraphs, add_special_tokens=False)\n",
    "dev_paragraphs_tokenized = tokenizer(dev_paragraphs, add_special_tokens=False)\n",
    "test_paragraphs_tokenized = tokenizer(test_paragraphs, add_special_tokens=False)\n",
    "\n",
    "# You can safely ignore the warning message as tokenized sequences will be futher processed in datset __getitem__ before passing to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1807, 100, 1967, 1916, 100, 100, 1742, 100, 1873, 100, 100, 100, 100, 1029]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print (test_questions_tokenized.data['input_ids'][0])\n",
    "print (test_questions_tokenized.data['token_type_ids'][0])\n",
    "print (test_questions_tokenized.data['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [len(train_paragrpah) for train_paragrpah in train_paragraphs_tokenized.data['input_ids']]\n",
    "num_bins = 12\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=num_bins, edgecolor='black')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution Bucket Diagram')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "#print((train_paragraphs_tokenized.data['input_ids'][0]))\n",
    "#print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 1980, 100, 1917, 100, 100, 1741, 1745, 100, 5385, 1840, 1888, 100, 1779, 100, 100, 100, 100, 1980, 1756, 1916, 1917, 1838, 1029]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print (train_questions_tokenized.data['input_ids'][0])\n",
    "print (train_questions_tokenized.data['token_type_ids'][0])\n",
    "print (train_questions_tokenized.data['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(test_questions_tokenized.data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws8c8_4d5UCI"
   },
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Xjooag-Swnuh"
   },
   "outputs": [],
   "source": [
    "class QA_Dataset(Dataset):\n",
    "    def __init__(self, split, questions, tokenized_questions, tokenized_paragraphs):\n",
    "        self.split = split\n",
    "        self.questions = questions\n",
    "        self.tokenized_questions = tokenized_questions\n",
    "        self.tokenized_paragraphs = tokenized_paragraphs\n",
    "        self.max_question_len = 40\n",
    "        self.max_paragraph_len = 150\n",
    "\n",
    "        ##### TODO: Change value of doc_stride #####\n",
    "        self.doc_stride = 75\n",
    "\n",
    "        # Input sequence length = [CLS] + question + [SEP] + paragraph + [SEP]\n",
    "        self.max_seq_len = 1 + self.max_question_len + 1 + self.max_paragraph_len + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        tokenized_question = self.tokenized_questions[idx]\n",
    "        tokenized_paragraph = self.tokenized_paragraphs[question[\"paragraph_id\"]]\n",
    "\n",
    "        ##### TODO: Preprocessing #####\n",
    "        # Hint: How to prevent model from learning something it should not learn\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            # Convert answer's start/end positions in paragraph_text to start/end positions in tokenized_paragraph\n",
    "            answer_start_token = tokenized_paragraph.char_to_token(question[\"answer_start\"])\n",
    "            answer_end_token = tokenized_paragraph.char_to_token(question[\"answer_end\"])\n",
    "\n",
    "            # A single window is obtained by slicing the portion of paragraph containing the answer\n",
    "            mid = (answer_start_token + answer_end_token) // 2\n",
    "            paragraph_start = max(0, min(mid - self.max_paragraph_len // 2, len(tokenized_paragraph) - self.max_paragraph_len))\n",
    "            paragraph_end = paragraph_start + self.max_paragraph_len\n",
    "\n",
    "            # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n",
    "            input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102]\n",
    "            input_ids_paragraph = tokenized_paragraph.ids[paragraph_start : paragraph_end] + [102]\n",
    "\n",
    "            # Convert answer's start/end positions in tokenized_paragraph to start/end positions in the window\n",
    "            answer_start_token += len(input_ids_question) - paragraph_start\n",
    "            answer_end_token += len(input_ids_question) - paragraph_start\n",
    "\n",
    "            # Pad sequence and obtain inputs to model\n",
    "            input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n",
    "            return torch.tensor(input_ids), torch.tensor(token_type_ids), torch.tensor(attention_mask), answer_start_token, answer_end_token\n",
    "\n",
    "        # Validation/Testing\n",
    "        else:\n",
    "            input_ids_list, token_type_ids_list, attention_mask_list = [], [], []\n",
    "\n",
    "            # Paragraph is split into several windows, each with start positions separated by step \"doc_stride\"\n",
    "            for i in range(0, len(tokenized_paragraph), self.doc_stride):\n",
    "\n",
    "                # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n",
    "                input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102]\n",
    "                input_ids_paragraph = tokenized_paragraph.ids[i : i + self.max_paragraph_len] + [102]\n",
    "\n",
    "                # Pad sequence and obtain inputs to model\n",
    "                input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n",
    "\n",
    "                input_ids_list.append(input_ids)\n",
    "                token_type_ids_list.append(token_type_ids)\n",
    "                attention_mask_list.append(attention_mask)\n",
    "\n",
    "            return torch.tensor(input_ids_list), torch.tensor(token_type_ids_list), torch.tensor(attention_mask_list)\n",
    "\n",
    "    def padding(self, input_ids_question, input_ids_paragraph):\n",
    "        # Pad zeros if sequence length is shorter than max_seq_len\n",
    "        padding_len = self.max_seq_len - len(input_ids_question) - len(input_ids_paragraph)\n",
    "        # Indices of input sequence tokens in the vocabulary\n",
    "        input_ids = input_ids_question + input_ids_paragraph + [0] * padding_len\n",
    "        # Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]\n",
    "        token_type_ids = [0] * len(input_ids_question) + [1] * len(input_ids_paragraph) + [0] * padding_len\n",
    "        # Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]\n",
    "        attention_mask = [1] * (len(input_ids_question) + len(input_ids_paragraph)) + [0] * padding_len\n",
    "\n",
    "        return input_ids, token_type_ids, attention_mask\n",
    "\n",
    "train_set = QA_Dataset(\"train\", train_questions, train_questions_tokenized, train_paragraphs_tokenized)\n",
    "dev_set = QA_Dataset(\"dev\", dev_questions, dev_questions_tokenized, dev_paragraphs_tokenized)\n",
    "test_set = QA_Dataset(\"test\", test_questions, test_questions_tokenized, test_paragraphs_tokenized)\n",
    "\n",
    "train_batch_size = 128\n",
    "\n",
    "# Note: Do NOT change batch size of dev_loader / test_loader !\n",
    "# Although batch size=1, it is actually a batch consisting of several windows from the same QA pair\n",
    "train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True, pin_memory=True)\n",
    "dev_loader = DataLoader(dev_set, batch_size=1, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_H1kqhR8CdM"
   },
   "source": [
    "## Function for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SqeA3PLPxOHu"
   },
   "outputs": [],
   "source": [
    "def evaluate(data, output):\n",
    "    ##### TODO: Postprocessing #####\n",
    "    # There is a bug and room for improvement in postprocessing\n",
    "    # Hint: Open your prediction file to see what is wrong\n",
    "\n",
    "    answer = ''\n",
    "    max_prob = float('-inf')\n",
    "    num_of_windows = data[0].shape[1]\n",
    "\n",
    "    for k in range(num_of_windows):\n",
    "        # Obtain answer by choosing the most probable start position / end position\n",
    "        start_prob, start_index = torch.max(output.start_logits[k], dim=0)\n",
    "        end_prob, end_index = torch.max(output.end_logits[k], dim=0)\n",
    "\n",
    "        # Probability of answer is calculated as sum of start_prob and end_prob\n",
    "        prob = start_prob + end_prob\n",
    "\n",
    "        if (start_index > end_index):\n",
    "            #pass\n",
    "            (start_index, end_index) = (end_index, start_index) # swap start and end if start > end\n",
    "\n",
    "        # Replace answer if calculated probability is larger than previous windows\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            # Convert tokens to chars (e.g. [1920, 7032] --> \"大 金\")\n",
    "            answer = tokenizer.decode(data[0][0][k][start_index : end_index + 1])\n",
    "\n",
    "    # Remove spaces in answer (e.g. \"大 金\" --> \"大金\")\n",
    "    return answer.replace(' ','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzHQit6eMnKG"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Q-B6ka7xoCM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuji/miniconda3/envs/bert/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ...\n",
      "<class 'torch.device'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7362eb9f413b4548b6282ad53ca761dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "num_epoch = 1\n",
    "validation = True\n",
    "logging_step = 100\n",
    "learning_rate = 1e-4\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_data_size = train_set.__len__()\n",
    "t_total = train_data_size // train_batch_size * num_epoch  # Total number of training steps\n",
    "warmup_steps = 0.1 * t_total  # Warmup steps as a fraction of total training steps\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
    ")\n",
    "\n",
    "if fp16_training:\n",
    "    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader)\n",
    "\n",
    "model.train()\n",
    "\n",
    "print(\"Start Training ...\")\n",
    "print(type(device))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    step = 1\n",
    "    train_loss = train_acc = 0\n",
    "\n",
    "    for data in tqdm(train_loader):\n",
    "        # Load all data into GPU\n",
    "        data = [i.to(device) for i in data]\n",
    "\n",
    "        # Model inputs: input_ids, token_type_ids, attention_mask, start_positions, end_positions (Note: only \"input_ids\" is mandatory)\n",
    "        # Model outputs: start_logits, end_logits, loss (return when start_positions/end_positions are provided)\n",
    "        #with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "        output = model(input_ids=data[0], token_type_ids=data[1], attention_mask=data[2], start_positions=data[3], end_positions=data[4])\n",
    "\n",
    "        # Choose the most probable start position / end position\n",
    "        start_index = torch.argmax(output.start_logits, dim=1)\n",
    "        end_index = torch.argmax(output.end_logits, dim=1)\n",
    "\n",
    "        # Prediction is correct only if both start_index and end_index are correct\n",
    "        train_acc += ((start_index == data[3]) & (end_index == data[4])).float().mean()\n",
    "        train_loss += output.loss\n",
    "\n",
    "        if fp16_training:\n",
    "            accelerator.backward(output.loss)\n",
    "        else:\n",
    "            output.loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        step += 1\n",
    "\n",
    "        ##### TODO: Apply linear learning rate decay #####\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        lr -= lr / step / step\n",
    "        if (lr < 0):\n",
    "            lr = -lr\n",
    "        #optimizer.param_groups[0]['lr'] = lr\n",
    "        if (step % 10 == 0):\n",
    "            pass\n",
    "            #print(lr)\n",
    "\n",
    "        \n",
    "\n",
    "        # Print training loss and accuracy over past logging step\n",
    "        if step % logging_step == 0:\n",
    "            print(f\"Epoch {epoch + 1} | Step {step} | loss = {train_loss.item() / logging_step:.3f}, acc = {train_acc / logging_step:.3f}\")\n",
    "            train_loss = train_acc = 0\n",
    "\n",
    "    if validation:\n",
    "        print(\"Evaluating Dev Set ...\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            dev_acc = 0\n",
    "            for i, data in enumerate(tqdm(dev_loader)):\n",
    "                #with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "                output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n",
    "                       attention_mask=data[2].squeeze(dim=0).to(device))\n",
    "                # prediction is correct only if answer text exactly matches\n",
    "                dev_acc += evaluate(data, output) == dev_questions[i][\"answer_text\"]\n",
    "            print(f\"Validation | Epoch {epoch + 1} | acc = {dev_acc / len(dev_loader):.3f}\")\n",
    "        model.train()\n",
    "\n",
    "# Save a model and its configuration file to the directory 「saved_model」\n",
    "# i.e. there are two files under the direcory 「saved_model」: 「pytorch_model.bin」 and 「config.json」\n",
    "# Saved model can be re-loaded using 「model = BertForQuestionAnswering.from_pretrained(\"saved_model\")」\n",
    "print(\"Saving Model ...\")\n",
    "model_save_dir = \"saved_model\"\n",
    "model.save_pretrained(model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMmdLOKBMsdE"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "U5scNKC9xz0C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9935f087d9442f999a31e25826b9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4957 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed! Result is in result.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Test Set ...\")\n",
    "\n",
    "result = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader):\n",
    "        output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n",
    "                       attention_mask=data[2].squeeze(dim=0).to(device))\n",
    "        result.append(evaluate(data, output))\n",
    "\n",
    "result_file = \"result.csv\"\n",
    "with open(result_file, 'w') as f:\n",
    "\t  f.write(\"ID,Answer\\n\")\n",
    "\t  for i, test_question in enumerate(test_questions):\n",
    "        # Replace commas in answers with empty strings (since csv is separated by comma)\n",
    "        # Answers in kaggle are processed in the same way\n",
    "\t\t    f.write(f\"{test_question['id']},{result[i].replace(',','')}\\n\")\n",
    "\n",
    "print(f\"Completed! Result is in {result_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 3493170,
     "sourceId": 35999,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30528,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
